# æ•°æ®åº“æ›¿ä»£æ–¹æ¡ˆè¯¦ç»†åˆ†æ

## ğŸ—„ï¸ **æ•°æ®åº“é€‰æ‹©å¯¹æ¯”**

### **æ–¹æ¡ˆ1: Cloudflare D1 (æ¨è)**
```sql
-- ä¼˜åŠ¿ï¼š
-- âœ… åŸç”Ÿé›†æˆCloudflare Workers
-- âœ… æ— æœåŠ¡å™¨ï¼Œè‡ªåŠ¨æ‰©å±•
-- âœ… æ‰¹é‡æ“ä½œæ”¯æŒ
-- âœ… æ— è¿æ¥é™åˆ¶

CREATE TABLE articles (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  url TEXT UNIQUE NOT NULL,
  title TEXT NOT NULL,
  title_hash TEXT,
  content TEXT,
  published_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  source_feed TEXT,
  ai_processed BOOLEAN DEFAULT FALSE
);

-- æ‰¹é‡æ’å…¥ç¤ºä¾‹
INSERT OR IGNORE INTO articles (url, title, title_hash, content, source_feed)
VALUES 
  ('url1', 'title1', 'hash1', 'content1', 'feed1'),
  ('url2', 'title2', 'hash2', 'content2', 'feed2'),
  -- ... æ‰¹é‡æ’å…¥100ç¯‡
  ('url100', 'title100', 'hash100', 'content100', 'feed100');

-- æ‰¹é‡å»é‡æ£€æŸ¥
SELECT url FROM articles WHERE url IN ('url1', 'url2', ..., 'url100');
```

### **æ–¹æ¡ˆ2: PostgreSQL (é«˜æ€§èƒ½)**
```javascript
// Neon.tech/Supabaseç­‰æœåŠ¡
const pool = new Pool({
  connectionString: env.DATABASE_URL,
  max: 20 // è¿æ¥æ± 
});

// æ‰¹é‡upsert
await pool.query(`
  INSERT INTO articles (url, title, content, source_feed)
  SELECT * FROM unnest($1::text[], $2::text[], $3::text[], $4::text[])
  ON CONFLICT (url) DO NOTHING
`, [urls, titles, contents, feeds]);
```

### **æ–¹æ¡ˆ3: Redis + PostgreSQL æ··åˆ**
```javascript
// Redisç¼“å­˜ + PostgreSQLæŒä¹…åŒ–
const redis = new Redis(env.REDIS_URL);
const pg = new Pool({ connectionString: env.DATABASE_URL });

// 1. Rediså¿«é€Ÿå»é‡
const existingUrls = await redis.sismember('processed_urls', urlsToCheck);

// 2. PostgreSQLæ‰¹é‡å†™å…¥
await pg.query('INSERT INTO articles ... ON CONFLICT DO NOTHING');

// 3. Redisæ›´æ–°ç¼“å­˜
await redis.sadd('processed_urls', newUrls);
```

## ğŸ“Š **æ€§èƒ½å¯¹æ¯”**

| æ–¹æ¡ˆ | å»é‡é€Ÿåº¦ | æ‰¹é‡å†™å…¥ | æˆæœ¬ | å¤æ‚åº¦ |
|------|----------|----------|------|--------|
| Cloudflare KV | 50ms/ç¯‡ | ä¸æ”¯æŒ | ä½ | ç®€å• |
| D1 SQLite | 1ms/æ‰¹æ¬¡ | âœ… æ”¯æŒ | ä½ | ç®€å• |
| PostgreSQL | 0.5ms/æ‰¹æ¬¡ | âœ… ä¼˜ç§€ | ä¸­ | ä¸­ç­‰ |
| Redis+PG | 0.1ms/æ‰¹æ¬¡ | âœ… æœ€ä¼˜ | é«˜ | å¤æ‚ |

## ğŸš€ **å®æ–½å»ºè®®**

### **ç«‹å³æ–¹æ¡ˆï¼šå¯ç”¨D1æ•°æ®åº“**
```toml
# wrangler.toml
[[d1_databases]]
binding = "DB"
database_name = "siji-articles"
database_id = "your-d1-id"
```

### **ä»£ç æ”¹é€ ç¤ºä¾‹**
```javascript
// æ›¿æ¢KVçš„æ‰¹é‡å»é‡
async function batchCheckDuplicatesDB(env, articles) {
  const urls = articles.map(a => `'${normalizeUrl(a.link)}'`).join(',');
  
  const result = await env.DB.prepare(`
    SELECT url FROM articles WHERE url IN (${urls})
  `).all();
  
  const existingUrls = new Set(result.results.map(r => r.url));
  return articles.filter(a => !existingUrls.has(normalizeUrl(a.link)));
}

// æ‰¹é‡æ’å…¥æ–°æ–‡ç« 
async function batchInsertArticles(env, articles) {
  const values = articles.map(a => `(
    '${normalizeUrl(a.link)}',
    '${a.title.replace(/'/g, "''")}',
    '${generateTitleHash(a.title)}',
    '${a.description?.replace(/'/g, "''")}',
    '${a.feedUrl}'
  )`).join(',');
  
  await env.DB.prepare(`
    INSERT OR IGNORE INTO articles (url, title, title_hash, content, source_feed)
    VALUES ${values}
  `).run();
}
```

## ğŸ¯ **è¿ç§»è®¡åˆ’**

### **é˜¶æ®µ1: D1å‡†å¤‡** (1å°æ—¶)
1. åˆ›å»ºD1æ•°æ®åº“
2. è¿è¡Œå»ºè¡¨SQL
3. é…ç½®wrangler.toml

### **é˜¶æ®µ2: ä»£ç è¿ç§»** (2å°æ—¶)  
1. æ›¿æ¢checkDuplicateså‡½æ•°
2. å®ç°æ‰¹é‡æ“ä½œ
3. æµ‹è¯•éªŒè¯

### **é˜¶æ®µ3: æ•°æ®è¿ç§»** (å¯é€‰)
1. ä»KVå¯¼å‡ºç°æœ‰æ•°æ®
2. å¯¼å…¥åˆ°D1
3. éªŒè¯æ•°æ®å®Œæ•´æ€§

## ğŸ’° **æˆæœ¬åˆ†æ**

- **D1**: $0.001/1M reads, $1/1M writes
- **å½“å‰KV**: $0.50/1M reads, $5/1M writes  
- **é¢„æœŸèŠ‚çœ**: 80-90% æ•°æ®åº“æˆæœ¬

## âš¡ **ç«‹å³è¡ŒåŠ¨**

æ‚¨å¸Œæœ›æˆ‘ç«‹å³å®æ–½å“ªä¸ªæ–¹æ¡ˆï¼Ÿ
1. **D1æ•°æ®åº“è¿ç§»** (æ¨èï¼Œå½»åº•è§£å†³)
2. **Cloudflare Queues** (æ¶æ„ä¼˜åŒ–)
3. **å¢é‡æŠ“å–** (å‡å°‘æ— æ•ˆè¯·æ±‚)
4. **ç»§ç»­å½“å‰ç´§æ€¥æ¨¡å¼** (ä¸´æ—¶æ–¹æ¡ˆ)